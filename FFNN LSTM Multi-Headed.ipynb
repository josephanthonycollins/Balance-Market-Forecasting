{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa18cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import importlib\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from math import floor\n",
    "from bayes_opt import BayesianOptimization\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "#tensorflow &keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input \n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "\n",
    "#sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing as prep\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3392be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format=\"%m/%d/%Y %H:%M\"\n",
    "date_parse = lambda date: dt.datetime.strptime(date, date_format)\n",
    "dat = pd.read_csv(\"C:/Users/coconnor/Documents/BM_data.csv\", index_col=\"SettlementPeriod\", parse_dates=True, date_parser=date_parse)\n",
    "\n",
    "dat = dat.drop([\"index\"], axis=1)\n",
    "dat=pd.DataFrame(dat)\n",
    "dat=dat.bfill(axis ='rows')\n",
    "dat=dat.ffill(axis ='rows')\n",
    "dat=dat._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a90e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dat.iloc[:, 0:16]\n",
    "X=dat.iloc[:,16:]\n",
    "X_train=X.iloc[:8738,:]\n",
    "Y_train=Y.iloc[:8738,:]\n",
    "X_test=X.iloc[8738:8739,:]\n",
    "Y_test=Y.iloc[8738:8739,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f404b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train_LSTM_1=X_train[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\",\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\",\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "rnn_train_LSTM_2=X_train[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\",\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\",\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "rnn_train_LSTM_3=X_train[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\",\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\",\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "rnn_train_LSTM_4=X_train[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\", \"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\", \"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "rnn_train_LSTM_5=X_train[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\",\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\",\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "rnn_test_LSTM_1=X_test[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\",\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\",\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "rnn_test_LSTM_2=X_test[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\",\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\",\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "rnn_test_LSTM_3=X_test[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\",\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\",\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "rnn_test_LSTM_4=X_test[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\", \"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\", \"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "rnn_test_LSTM_5=X_test[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\",\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\",\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "rnn_train_ffnn_1=X_train[[\"lag_2x7\",\"lag_3x7\",\"lag_4x7\",\"lag_5x7\",\"lag_6x7\",\"lag_7x7\",\"lag_8x7\",\"lag_9x7\",\"lag_10x7\",\"lag_11x7\",\"lag_12x7\",\"lag_13x7\",\"lag_14x7\",\"lag_15x7\",\"lag_16x7\",\"lag_17x7\"]]\n",
    "rnn_train_ffnn_2=X_train[[\"lag_2x8.1\",\"lag_3x8\",\"lag_4x8\",\"lag_5x8\",\"lag_6x8\",\"lag_7x8\",\"lag_8x8\",\"lag_9x8\",\"lag_10x8\",\"lag_11x8\",\"lag_12x8\",\"lag_13x8\",\"lag_14x8\",\"lag_15x8\",\"lag_16x8\",\"lag_17x8\"]]\n",
    "rnn_train_ffnn_3=X_train[[\"lag_2x9\",\"lag_3x9\",\"lag_4x9\",\"lag_5x9\",\"lag_6x9\",\"lag_7x9\",\"lag_8x9\",\"lag_9x9\",\"lag_10x9\",\"lag_11x9\",\"lag_12x9\",\"lag_13x9\",\"lag_14x9\",\"lag_15x9\",\"lag_16x9\",\"lag_17x9\"]]\n",
    "rnn_train_ffnn_4=X_train[[\"lag_2x10\",\"lag_3x10\",\"lag_4x10\",\"lag_5x10\",\"lag_6x10\",\"lag_7x10\",\"lag_8x10\",\"lag_9x10\",\"lag_10x10\",\"lag_11x10\",\"lag_12x10\",\"lag_13x10\",\"lag_14x10\",\"lag_15x10\",\"lag_16x10\",\"lag_17x10\"]]\n",
    "rnn_train_ffnn_5=X_train[[\"lag_2x11\",\"lag_3x11\",\"lag_4x11\",\"lag_5x11\",\"lag_6x11\",\"lag_7x11\",\"lag_8x11\",\"lag_9x11\",\"lag_10x11\",\"lag_11x11\",\"lag_12x11\",\"lag_13x11\",\"lag_14x11\",\"lag_15x11\",\"lag_16x11\",\"lag_17x11\"]]\n",
    "\n",
    "rnn_test_ffnn_1=X_test[[\"lag_2x7\",\"lag_3x7\",\"lag_4x7\",\"lag_5x7\",\"lag_6x7\",\"lag_7x7\",\"lag_8x7\",\"lag_9x7\",\"lag_10x7\",\"lag_11x7\",\"lag_12x7\",\"lag_13x7\",\"lag_14x7\",\"lag_15x7\",\"lag_16x7\",\"lag_17x7\"]]\n",
    "rnn_test_ffnn_2=X_test[[\"lag_2x8.1\",\"lag_3x8\",\"lag_4x8\",\"lag_5x8\",\"lag_6x8\",\"lag_7x8\",\"lag_8x8\",\"lag_9x8\",\"lag_10x8\",\"lag_11x8\",\"lag_12x8\",\"lag_13x8\",\"lag_14x8\",\"lag_15x8\",\"lag_16x8\",\"lag_17x8\"]]\n",
    "rnn_test_ffnn_3=X_test[[\"lag_2x9\",\"lag_3x9\",\"lag_4x9\",\"lag_5x9\",\"lag_6x9\",\"lag_7x9\",\"lag_8x9\",\"lag_9x9\",\"lag_10x9\",\"lag_11x9\",\"lag_12x9\",\"lag_13x9\",\"lag_14x9\",\"lag_15x9\",\"lag_16x9\",\"lag_17x9\"]]\n",
    "rnn_test_ffnn_4=X_test[[\"lag_2x10\",\"lag_3x10\",\"lag_4x10\",\"lag_5x10\",\"lag_6x10\",\"lag_7x10\",\"lag_8x10\",\"lag_9x10\",\"lag_10x10\",\"lag_11x10\",\"lag_12x10\",\"lag_13x10\",\"lag_14x10\",\"lag_15x10\",\"lag_16x10\",\"lag_17x10\"]]\n",
    "rnn_test_ffnn_5=X_test[[\"lag_2x11\",\"lag_3x11\",\"lag_4x11\",\"lag_5x11\",\"lag_6x11\",\"lag_7x11\",\"lag_8x11\",\"lag_9x11\",\"lag_10x11\",\"lag_11x11\",\"lag_12x11\",\"lag_13x11\",\"lag_14x11\",\"lag_15x11\",\"lag_16x11\",\"lag_17x11\"]]\n",
    "\n",
    "rnn_Y=Y_train[[\"lag_2y\", \"lag_3y\", \"lag_4y\", \"lag_5y\", \"lag_6y\", \"lag_7y\", \"lag_8y\", \"lag_9y\", \"lag_10y\", \"lag_11y\", \"lag_12y\", \"lag_13y\", \"lag_14y\", \"lag_15y\", \"lag_16y\", \"lag_17y\"]]\n",
    "\n",
    "X_scaler_LSTM_1 = preprocessing.MinMaxScaler()\n",
    "X_scaler_LSTM_2 = preprocessing.MinMaxScaler()\n",
    "X_scaler_LSTM_3 = preprocessing.MinMaxScaler()\n",
    "X_scaler_LSTM_4 = preprocessing.MinMaxScaler()\n",
    "X_scaler_LSTM_5 = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_scaler_ffnn_1 = preprocessing.MinMaxScaler()\n",
    "X_scaler_ffnn_2 = preprocessing.MinMaxScaler()\n",
    "X_scaler_ffnn_3 = preprocessing.MinMaxScaler()\n",
    "X_scaler_ffnn_4 = preprocessing.MinMaxScaler()\n",
    "X_scaler_ffnn_5 = preprocessing.MinMaxScaler()\n",
    "\n",
    "Y_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "rnn_scaled_train_LSTM_1 = X_scaler_LSTM_1.fit_transform(rnn_train_LSTM_1)\n",
    "rnn_scaled_train_LSTM_2 = X_scaler_LSTM_2.fit_transform(rnn_train_LSTM_2)\n",
    "rnn_scaled_train_LSTM_3 = X_scaler_LSTM_3.fit_transform(rnn_train_LSTM_3)\n",
    "rnn_scaled_train_LSTM_4 = X_scaler_LSTM_4.fit_transform(rnn_train_LSTM_4)\n",
    "rnn_scaled_train_LSTM_5 = X_scaler_LSTM_5.fit_transform(rnn_train_LSTM_5)\n",
    "\n",
    "rnn_scaled_train_ffnn_1 = X_scaler_ffnn_1.fit_transform(rnn_train_ffnn_1)\n",
    "rnn_scaled_train_ffnn_2 = X_scaler_ffnn_2.fit_transform(rnn_train_ffnn_2)\n",
    "rnn_scaled_train_ffnn_3 = X_scaler_ffnn_3.fit_transform(rnn_train_ffnn_3)\n",
    "rnn_scaled_train_ffnn_4 = X_scaler_ffnn_4.fit_transform(rnn_train_ffnn_4)\n",
    "rnn_scaled_train_ffnn_5 = X_scaler_ffnn_5.fit_transform(rnn_train_ffnn_5)\n",
    "\n",
    "Y_train_Scaled   = Y_scaler.fit_transform(Y_train)\n",
    "\n",
    "X_train_Scaled_LSTM = np.hstack(\n",
    "    (rnn_scaled_train_LSTM_1, rnn_scaled_train_LSTM_2, rnn_scaled_train_LSTM_3,\n",
    "     rnn_scaled_train_LSTM_4, rnn_scaled_train_LSTM_5)\n",
    ").reshape(rnn_train_LSTM_1.shape[0], 5, 48).transpose(0, 2, 1)\n",
    "\n",
    "X_train_Scaled_ffnn = np.hstack(\n",
    "    (rnn_scaled_train_ffnn_1, rnn_scaled_train_ffnn_2, rnn_scaled_train_ffnn_3,\n",
    "     rnn_scaled_train_ffnn_4, rnn_scaled_train_ffnn_5)\n",
    ").reshape(rnn_train_ffnn_1.shape[0], 5, 16).transpose(0, 2, 1)\n",
    "\n",
    "X_test_Scaled_LSTM = np.hstack(\n",
    "    (X_scaler_LSTM_1.transform(rnn_test_LSTM_1), X_scaler_LSTM_2.transform(rnn_test_LSTM_2),\n",
    "     X_scaler_LSTM_3.transform(rnn_test_LSTM_3), X_scaler_LSTM_4.transform(rnn_test_LSTM_4),\n",
    "     X_scaler_LSTM_5.transform(rnn_test_LSTM_5))\n",
    ").reshape(rnn_test_LSTM_1.shape[0], 5, 48).transpose(0, 2, 1)\n",
    "\n",
    "X_test_Scaled_ffnn = np.hstack(\n",
    "    (X_scaler_ffnn_1.transform(rnn_test_ffnn_1), X_scaler_ffnn_2.transform(rnn_test_ffnn_2),\n",
    "     X_scaler_ffnn_3.transform(rnn_test_ffnn_3), X_scaler_ffnn_4.transform(rnn_test_ffnn_4),\n",
    "     X_scaler_ffnn_5.transform(rnn_test_ffnn_5))\n",
    ").reshape(rnn_test_ffnn_1.shape[0], 5, 16).transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16db46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_acc = make_scorer(mean_absolute_error)\n",
    "mae = make_scorer(MAE, greater_is_better=False)\n",
    "i_shape_lstm=(X_train_Scaled_LSTM.shape[1], X_train_Scaled_LSTM.shape[2])\n",
    "i_shape_ffnn=(X_train_Scaled_ffnn.shape[1], X_train_Scaled_ffnn.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781cc272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "437/437 - 25s - loss: 0.0368 - mean_absolute_error: 0.0368 - val_loss: 0.0372 - val_mean_absolute_error: 0.0372 - 25s/epoch - 58ms/step\n",
      "Epoch 2/5\n",
      "437/437 - 22s - loss: 0.0349 - mean_absolute_error: 0.0349 - val_loss: 0.0364 - val_mean_absolute_error: 0.0364 - 22s/epoch - 50ms/step\n",
      "Epoch 3/5\n",
      "437/437 - 25s - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363 - 25s/epoch - 58ms/step\n",
      "Epoch 4/5\n",
      "437/437 - 26s - loss: 0.0346 - mean_absolute_error: 0.0346 - val_loss: 0.0365 - val_mean_absolute_error: 0.0365 - 26s/epoch - 60ms/step\n",
      "Epoch 5/5\n",
      "437/437 - 26s - loss: 0.0344 - mean_absolute_error: 0.0344 - val_loss: 0.0362 - val_mean_absolute_error: 0.0362 - 26s/epoch - 60ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>910.236517</td>\n",
       "      <td>30.170126</td>\n",
       "      <td>25.018598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2\n",
       "0  910.236517  30.170126  25.018598"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visible1 = Input(shape=(i_shape_lstm))\n",
    "for i in range(3):\n",
    "    dense1 = LSTM(256, return_sequences= True, input_shape=i_shape_lstm)(visible1)\n",
    "\n",
    "for i in range(3):\n",
    "    dense2 = LSTM(64, return_sequences= True, input_shape=i_shape_lstm)(dense1)\n",
    "\n",
    "dense3 = LSTM(16)(dense2)\n",
    "flat1=Flatten()(dense3)\n",
    "\n",
    "visible2 = Input(shape=(i_shape_ffnn))\n",
    "for i in range(3):\n",
    "    dense4 = Dense(100, activation='tanh')(visible2)\n",
    "for i in range(3):\n",
    "    dense5 = Dense(64, activation='relu')(dense4)\n",
    "dense6 = Dense(16, activation='tanh')(dense5)\n",
    "flat2=Flatten()(dense6)\n",
    "\n",
    "merged = concatenate([flat1, flat2])\n",
    "\n",
    "for i in range(3):\n",
    "    dense_f = Dense(100, activation='tanh')(merged)\n",
    "outputs = Dense(16, activation='sigmoid')(dense_f)\n",
    "\n",
    "model = Model(inputs=[visible1, visible2], outputs=outputs)\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer= 'Adam', metrics=['mean_absolute_error'])\n",
    "es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=2, patience=20)        \n",
    "model.fit([X_train_Scaled_LSTM, X_train_Scaled_ffnn], Y_train_Scaled, verbose=2, epochs=5,\n",
    "          batch_size=16, validation_split=0.2, callbacks=[es])\n",
    "\n",
    "preds_nn = pd.DataFrame(Y_scaler.inverse_transform(model.predict([X_test_Scaled_LSTM ,X_test_Scaled_ffnn]).reshape(1,16)), index=Y_test.index)\n",
    "mse = mean_squared_error(Y_test, preds_nn)\n",
    "rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "mae = mean_absolute_error(Y_test, preds_nn)\n",
    "Error_1 = pd.DataFrame([mse, rmse, mae]).T\n",
    "Error_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac0eb421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "437/437 - 27s - loss: 0.0366 - mean_absolute_error: 0.0366 - val_loss: 0.0367 - val_mean_absolute_error: 0.0367 - 27s/epoch - 63ms/step\n",
      "Epoch 2/5\n",
      "437/437 - 25s - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363 - 25s/epoch - 57ms/step\n",
      "Epoch 3/5\n",
      "437/437 - 26s - loss: 0.0347 - mean_absolute_error: 0.0347 - val_loss: 0.0362 - val_mean_absolute_error: 0.0362 - 26s/epoch - 59ms/step\n",
      "Epoch 4/5\n",
      "437/437 - 25s - loss: 0.0346 - mean_absolute_error: 0.0346 - val_loss: 0.0365 - val_mean_absolute_error: 0.0365 - 25s/epoch - 58ms/step\n",
      "Epoch 5/5\n",
      "437/437 - 26s - loss: 0.0345 - mean_absolute_error: 0.0345 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363 - 26s/epoch - 60ms/step\n",
      "1/1 - 1s - 963ms/epoch - 963ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330.514064</td>\n",
       "      <td>36.476212</td>\n",
       "      <td>29.520985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2\n",
       "0  1330.514064  36.476212  29.520985"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_LSTM_fnn():\n",
    "    visible1 = Input(shape=(i_shape_lstm))\n",
    "    for i in range(3):\n",
    "        dense1 = LSTM(256, return_sequences= True, input_shape=i_shape_lstm)(visible1)\n",
    "\n",
    "    for i in range(3):\n",
    "        dense2 = LSTM(64, return_sequences= True, input_shape=i_shape_lstm)(dense1)\n",
    "\n",
    "    dense3 = LSTM(16)(dense2)\n",
    "    flat1=Flatten()(dense3)\n",
    "    \n",
    "    visible2 = Input(shape=(i_shape_ffnn))\n",
    "    for i in range(3):\n",
    "        dense4 = Dense(100, activation='tanh')(visible2)\n",
    "        \n",
    "    for i in range(3):\n",
    "        dense5 = Dense(64, activation='relu')(dense4)\n",
    "        \n",
    "    dense6 = Dense(16, activation='tanh')(dense5)\n",
    "    flat2=Flatten()(dense6)\n",
    "    \n",
    "    merged = concatenate([flat1, flat2])\n",
    "\n",
    "    for i in range(3):\n",
    "        dense_f = Dense(100, activation='tanh')(merged)\n",
    "        \n",
    "    outputs = Dense(16, activation='sigmoid')(dense_f)\n",
    "\n",
    "    model = Model(inputs=[visible1, visible2], outputs=outputs)\n",
    "    \n",
    "    model.compile(loss='mean_absolute_error', optimizer= 'Adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model\n",
    "\n",
    "es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=2, patience=20)        \n",
    "nn_hyp = KerasRegressor(build_fn=model_LSTM_fnn, epochs=5, batch_size=16,\n",
    "                         verbose=2, callbacks=[es])\n",
    "nn_hyp.fit([X_train_Scaled_LSTM, X_train_Scaled_ffnn], Y_train_Scaled, verbose=2, validation_split=0.2)\n",
    "preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict([X_test_Scaled_LSTM ,X_test_Scaled_ffnn]).reshape(1,16)), index=Y_test.index)\n",
    "mse = mean_squared_error(Y_test, preds_nn)\n",
    "rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "mae = mean_absolute_error(Y_test, preds_nn)\n",
    "Error_1 = pd.DataFrame([mse, rmse, mae]).T\n",
    "Error_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c57cdc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "437/437 - 28s - loss: 0.0365 - mean_absolute_error: 0.0365 - val_loss: 0.0374 - val_mean_absolute_error: 0.0374 - 28s/epoch - 63ms/step\n",
      "Epoch 2/5\n",
      "437/437 - 26s - loss: 0.0347 - mean_absolute_error: 0.0347 - val_loss: 0.0359 - val_mean_absolute_error: 0.0359 - 26s/epoch - 59ms/step\n",
      "Epoch 3/5\n",
      "437/437 - 26s - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0360 - val_mean_absolute_error: 0.0360 - 26s/epoch - 61ms/step\n",
      "Epoch 4/5\n",
      "437/437 - 26s - loss: 0.0346 - mean_absolute_error: 0.0346 - val_loss: 0.0361 - val_mean_absolute_error: 0.0361 - 26s/epoch - 60ms/step\n",
      "Epoch 5/5\n",
      "437/437 - 26s - loss: 0.0345 - mean_absolute_error: 0.0345 - val_loss: 0.0358 - val_mean_absolute_error: 0.0358 - 26s/epoch - 60ms/step\n",
      "1/1 - 1s - 884ms/epoch - 884ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1045.756052</td>\n",
       "      <td>32.338152</td>\n",
       "      <td>23.119179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2\n",
       "0  1045.756052  32.338152  23.119179"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_LSTM_fnn():\n",
    "    visible1 = Input(shape=(i_shape_lstm))\n",
    "    for i in range(3):\n",
    "        dense1 = LSTM(256, return_sequences= True, input_shape=i_shape_lstm)(visible1)\n",
    "\n",
    "    for i in range(3):\n",
    "        dense2 = LSTM(64, return_sequences= True, input_shape=i_shape_lstm)(dense1)\n",
    "\n",
    "    dense3 = LSTM(16)(dense2)\n",
    "    flat1=Flatten()(dense3)\n",
    "    \n",
    "    visible2 = Input(shape=(i_shape_ffnn))\n",
    "    for i in range(3):\n",
    "        dense4 = Dense(100, activation='tanh')(visible2)\n",
    "        \n",
    "    for i in range(3):\n",
    "        dense5 = Dense(64, activation='relu')(dense4)\n",
    "        \n",
    "    dense6 = Dense(16, activation='tanh')(dense5)\n",
    "    flat2=Flatten()(dense6)\n",
    "    \n",
    "    merged = concatenate([flat1, flat2])\n",
    "\n",
    "    for i in range(3):\n",
    "        dense_f = Dense(100, activation='tanh')(merged)\n",
    "        \n",
    "    outputs = Dense(16, activation='sigmoid')(dense_f)\n",
    "\n",
    "    model = Model(inputs=[visible1, visible2], outputs=outputs)\n",
    "    \n",
    "    model.compile(loss='mean_absolute_error', optimizer= 'Adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model\n",
    "\n",
    "es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=2, patience=20)        \n",
    "nn_hyp = KerasRegressor(build_fn=model_LSTM_fnn, epochs=5, batch_size=16,\n",
    "                         verbose=2, callbacks=[es])\n",
    "nn_hyp.fit([X_train_Scaled_LSTM, X_train_Scaled_ffnn], Y_train_Scaled, verbose=2, validation_split=0.2)\n",
    "preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict([X_test_Scaled_LSTM ,X_test_Scaled_ffnn]).reshape(1,16)), index=Y_test.index)\n",
    "mse = mean_squared_error(Y_test, preds_nn)\n",
    "rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "mae = mean_absolute_error(Y_test, preds_nn)\n",
    "Error_1 = pd.DataFrame([mse, rmse, mae]).T\n",
    "Error_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367bbede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "437/437 - 36s - loss: 0.0484 - mean_absolute_error: 0.0484 - val_loss: 0.0384 - val_mean_absolute_error: 0.0384 - 36s/epoch - 82ms/step\n",
      "Epoch 2/2\n",
      "437/437 - 30s - loss: 0.0353 - mean_absolute_error: 0.0353 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363 - 30s/epoch - 70ms/step\n",
      "1/1 - 1s - 1s/epoch - 1s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>522.595305</td>\n",
       "      <td>22.860344</td>\n",
       "      <td>14.368522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2\n",
       "0  522.595305  22.860344  14.368522"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_LSTM_fnn():\n",
    "    \n",
    "            visible1 = Input(shape=(i_shape_lstm))\n",
    "            \n",
    "            for i in range(3):\n",
    "                dense1 = LSTM(128, return_sequences= True, input_shape=i_shape_lstm)(visible1)\n",
    "\n",
    "            for i in range(2):\n",
    "                dense2 = LSTM(128, return_sequences= True, input_shape=i_shape_lstm)(dense1)\n",
    "                \n",
    "#             if 1 > 0.2:\n",
    "#                 dense_2=add(Dropout(0.1, seed=123))\n",
    "\n",
    "            for i in range(2):\n",
    "                dense3 = LSTM(128, return_sequences= True, input_shape=i_shape_lstm)(dense2)\n",
    "\n",
    "            dense4 = LSTM(16)(dense3)\n",
    "            flat1=Flatten()(dense4)\n",
    "    \n",
    "    \n",
    "            visible2 = Input(shape=(i_shape_ffnn))\n",
    "        \n",
    "            for i in range(3):\n",
    "                dense5 = Dense(128, activation='tanh')(visible2)\n",
    "        \n",
    "            for i in range(2):\n",
    "                dense6 = Dense(128, activation='relu')(dense5)\n",
    "                \n",
    "#             if 1 > 0.2:\n",
    "#                 nn_ffnn.add(Dropout(0.1, seed=123))\n",
    "                \n",
    "            for i in range(2):\n",
    "                dense7 = Dense(128, activation='sigmoid')(dense6)\n",
    "        \n",
    "            dense8 = Dense(128, activation='sigmoid')(dense7)\n",
    "            flat2=Flatten()(dense8)\n",
    "    \n",
    "            merged = concatenate([flat1, flat2])\n",
    "\n",
    "            for i in range(2):\n",
    "                dense_f = Dense(32, activation='relu')(merged)\n",
    "        \n",
    "            outputs = Dense(16, activation='sigmoid')(dense_f)\n",
    "\n",
    "            model = Model(inputs=[visible1, visible2], outputs=outputs)\n",
    "    \n",
    "            model.compile(loss='mean_absolute_error', optimizer= 'Adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "            return model\n",
    "        \n",
    "es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=2, patience=20)        \n",
    "nn_hyp = KerasRegressor(build_fn=model_LSTM_fnn, epochs=2, batch_size=16,\n",
    "                         verbose=2, callbacks=[es])\n",
    "nn_hyp.fit([X_train_Scaled_LSTM, X_train_Scaled_ffnn], Y_train_Scaled, verbose=2, validation_split=0.2)\n",
    "preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict([X_test_Scaled_LSTM ,X_test_Scaled_ffnn]).reshape(1,16)), index=Y_test.index)\n",
    "mse = mean_squared_error(Y_test, preds_nn)\n",
    "rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "mae = mean_absolute_error(Y_test, preds_nn)\n",
    "Error_1 = pd.DataFrame([mse, rmse, mae]).T\n",
    "Error_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75023927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4575285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout_lstm, dropout_rate_lstm, dropout_ffnn, dropout_rate_ffnn,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_neurons_0, lstm_neurons_1, lstm_neurons_2, lstm_neurons_3, ffnn_neurons_0, ffnn_neurons_1, ffnn_neurons_2,\n",
    "             ffnn_neurons_3,  batch_size, epochs, merged_layer,\n",
    "             dense_f_neurons, output_neurons, layers_lstm_1, layers_lstm_2, layers_lstm_3, layers_ffnn_1, layers_ffnn_2,\n",
    "             layers_ffnn_3, activation_0, activation_1, activation_2, activation_3, activation_4, activation_5):\n",
    "    \n",
    "            visible1 = Input(shape=(i_shape_lstm))\n",
    "            \n",
    "            for i in range(layers_lstm_1):\n",
    "                dense1 = LSTM(lstm_neurons_0, return_sequences= True, input_shape=i_shape_lstm)(visible1)\n",
    "\n",
    "            for i in range(layers_lstm_2):\n",
    "                dense2 = LSTM(lstm_neurons_1, return_sequences= True, input_shape=i_shape_lstm)(dense1)\n",
    "                \n",
    "#             if dropout_lstm > 0.2:\n",
    "#                 nn_ffnn.add(Dropout(dropout_rate_lstm, seed=123))\n",
    "\n",
    "            for i in range(layers_lstm_3):\n",
    "                dense3 = LSTM(lstm_neurons_2, return_sequences= True, input_shape=i_shape_lstm)(dense2)\n",
    "\n",
    "            dense4 = LSTM(lstm_neurons_3)(dense3)\n",
    "            flat1=Flatten()(dense4)\n",
    "    \n",
    "    \n",
    "            visible2 = Input(shape=(i_shape_ffnn))\n",
    "        \n",
    "            for i in range(layers_ffnn_1):\n",
    "                dense5 = Dense(ffnn_neurons_0, activation='activation_0')(visible2)\n",
    "        \n",
    "            for i in range(layers_ffnn_2):\n",
    "                dense6 = Dense(ffnn_neurons_1, activation='activation_1')(dense5)\n",
    "                \n",
    "#             if dropout_ffnn > 0.2:\n",
    "#                 nn_ffnn.add(Dropout(dropout_rate_ffnn, seed=123))\n",
    "                \n",
    "            for i in range(layers_ffnn_3):\n",
    "                dense7 = Dense(ffnn_neurons_2, activation='activation_2')(dense6)\n",
    "        \n",
    "            dense8 = Dense(ffnn_neurons_3, activation='activation_3')(dense7)\n",
    "            flat2=Flatten()(dense8)\n",
    "    \n",
    "            merged = concatenate([flat1, flat2])\n",
    "\n",
    "            for i in range(merged_layer):\n",
    "                dense_f = Dense(dense_f_neurons, activation='activation_4')(merged)\n",
    "        \n",
    "            outputs = Dense(output_neurons, activation='activation_5')(dense_f)\n",
    "\n",
    "            model = Model(inputs=[visible1, visible2], outputs=outputs)\n",
    "    \n",
    "            model.compile(loss='mean_absolute_error', optimizer= 'Adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "            return model\n",
    "        \n",
    "es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=0, patience=25)\n",
    "nn = KerasRegressor(build_fn=create_model,  verbose=2, callbacks=[es])\n",
    "# Set hyperparameters spaces\n",
    "params_nn ={\n",
    "    \n",
    "    'activation_0':['relu', 'sigmoid',  'tanh', LeakyReLU],\n",
    "    'activation_1':['relu', 'sigmoid',  'tanh', LeakyReLU],\n",
    "    'activation_2':['relu', 'sigmoid',  'tanh', LeakyReLU],\n",
    "    'activation_3':['relu', 'sigmoid',  'tanh', LeakyReLU],\n",
    "    'activation_4':['relu', 'sigmoid',  'tanh', LeakyReLU],\n",
    "    'activation_5':['relu', 'sigmoid',  'tanh', LeakyReLU],\n",
    "    \n",
    "    'lstm_neurons_0': (10, 500),\n",
    "    'lstm_neurons_1': (10, 500),\n",
    "    'lstm_neurons_2': (10, 500),\n",
    "    'lstm_neurons_3': (10, 500),\n",
    "    \n",
    "    'layers_lstm_1':(1,5),\n",
    "    'layers_lstm_2':(1,5),\n",
    "    'layers_lstm_3':(1,5),\n",
    "    \n",
    "    'ffnn_neurons_0': (10, 500),\n",
    "    'ffnn_neurons_1': (10, 500),\n",
    "    'ffnn_neurons_2': (10, 500),\n",
    "    'ffnn_neurons_3': (10, 500),\n",
    "\n",
    "    'layers_ffnn_1':(1,5),\n",
    "    'layers_ffnn_2':(1,5),\n",
    "    'layers_ffnn_3':(1,5),\n",
    "    \n",
    "    'merged_layer':(1,5),\n",
    "    'dense_f_neurons': (10, 500),\n",
    "    'output_neurons': (10, 500),\n",
    "\n",
    "#     'dropout_lstm':(0,1),\n",
    "#     'dropout_rate_lstm':(0,.5),\n",
    "    \n",
    "#     'dropout_ffnn':(0,1),\n",
    "#     'dropout_rate_ffnn':(0,.5),\n",
    "    \n",
    "    'batch_size':(8, 50),\n",
    "    'epochs':(10, 50)\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=nn, cv=5, param_distributions=params_nn)\n",
    "grid_result = grid.fit([X_train_Scaled_LSTM, X_train_Scaled_ffnn], Y_train_Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac951ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: \",\n",
    "      grid_result.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6e702a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77551430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout_lstm, dropout_rate_lstm, dropout_ffnn, dropout_rate_ffnn,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67563446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_re_bo(lstm_neurons_0, lstm_neurons_1, lstm_neurons_2, lstm_neurons_3, ffnn_neurons_0, ffnn_neurons_1, ffnn_neurons_2,\n",
    "             ffnn_neurons_3,   batch_size, epochs, merged_layer,\n",
    "             dense_f_neurons, output_neurons, layers_lstm_1, layers_lstm_2, layers_lstm_3, layers_ffnn_1, layers_ffnn_2,\n",
    "             layers_ffnn_3, activation_0, activation_1, activation_2, activation_3, activation_4, activation_5):\n",
    "    \n",
    "    optimizerL = ['Adam']\n",
    "    activationL = ['relu', 'sigmoid',  'tanh', LeakyReLU]\n",
    "\n",
    "    activation_0 = activationL[floor(activation_0)]\n",
    "    activation_1 = activationL[floor(activation_1)]\n",
    "    activation_2 = activationL[floor(activation_2)]\n",
    "    activation_3 = activationL[floor(activation_3)]\n",
    "    activation_4 = activationL[floor(activation_4)]\n",
    "    activation_5 = activationL[floor(activation_5)]\n",
    "\n",
    "    \n",
    "    lstm_neurons_0 = round(lstm_neurons_0)\n",
    "    lstm_neurons_1 = round(lstm_neurons_1)\n",
    "    lstm_neurons_2 = round(lstm_neurons_2)\n",
    "    lstm_neurons_3 = round(lstm_neurons_3)\n",
    "    \n",
    "    ffnn_neurons_0 = round(ffnn_neurons_0)\n",
    "    ffnn_neurons_1 = round(ffnn_neurons_1)\n",
    "    ffnn_neurons_2 = round(ffnn_neurons_2)\n",
    "    ffnn_neurons_3 = round(ffnn_neurons_3)\n",
    "\n",
    "    layers_lstm_1 = round(layers_lstm_1)\n",
    "    layers_lstm_2 = round(layers_lstm_2)\n",
    "    layers_lstm_3 = round(layers_lstm_3)\n",
    "    \n",
    "    layers_ffnn_1 = round(layers_ffnn_1)\n",
    "    layers_ffnn_2 = round(layers_ffnn_2)\n",
    "    layers_ffnn_3 = round(layers_ffnn_3)\n",
    "    \n",
    "    merged_layer    = round(merged_layer)\n",
    "    dense_f_neurons = round(dense_f_neurons)\n",
    "    output_neurons  = round(output_neurons)\n",
    "\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    \n",
    "\n",
    "\n",
    "    def model_LSTM_fnn():\n",
    "            visible1 = Input(shape=(i_shape_lstm))\n",
    "            \n",
    "            for i in range(layers_lstm_1):\n",
    "                dense1 = LSTM(lstm_neurons_0, return_sequences= True, input_shape=i_shape_lstm)(visible1)\n",
    "\n",
    "            for i in range(layers_lstm_2):\n",
    "                dense2 = LSTM(lstm_neurons_1, return_sequences= True, input_shape=i_shape_lstm)(dense1)\n",
    "                \n",
    "#             if dropout_lstm > 0.2:\n",
    "#                 nn_ffnn.add(Dropout(dropout_rate_lstm, seed=123))\n",
    "\n",
    "            for i in range(layers_lstm_3):\n",
    "                dense3 = LSTM(lstm_neurons_2, return_sequences= True, input_shape=i_shape_lstm)(dense2)\n",
    "\n",
    "            dense4 = LSTM(lstm_neurons_3)(dense3)\n",
    "            flat1=Flatten()(dense4)\n",
    "    \n",
    "    \n",
    "            visible2 = Input(shape=(i_shape_ffnn))\n",
    "        \n",
    "            for i in range(layers_ffnn_1):\n",
    "                dense5 = Dense(ffnn_neurons_0, activation='activation_0')(visible2)\n",
    "        \n",
    "            for i in range(layers_ffnn_2):\n",
    "                dense6 = Dense(ffnn_neurons_1, activation='activation_1')(dense5)\n",
    "                \n",
    "#             if dropout_ffnn > 0.2:\n",
    "#                 nn_ffnn.add(Dropout(dropout_rate_ffnn, seed=123))\n",
    "                \n",
    "            for i in range(layers_ffnn_3):\n",
    "                dense7 = Dense(ffnn_neurons_2, activation='activation_2')(dense6)\n",
    "        \n",
    "            dense8 = Dense(ffnn_neurons_3, activation='activation_3')(dense7)\n",
    "            flat2=Flatten()(dense8)\n",
    "    \n",
    "            merged = concatenate([flat1, flat2])\n",
    "\n",
    "            for i in range(merged_layer):\n",
    "                dense_f = Dense(dense_f_neurons, activation='activation_4')(merged)\n",
    "        \n",
    "            outputs = Dense(output_neurons, activation='activation_5')(dense_f)\n",
    "\n",
    "            model = Model(inputs=[visible1, visible2], outputs=outputs)\n",
    "    \n",
    "            model.compile(loss='mean_absolute_error', optimizer= 'Adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "            return model\n",
    "    \n",
    "        \n",
    "    es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=2, patience=25)\n",
    "    nn = KerasRegressor(build_fn=model_LSTM_fnn, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    scores = cross_val_score(nn, [X_train_Scaled_LSTM, X_train_Scaled_ffnn], Y_train_Scaled, scoring=mae, cv=5, fit_params={'callbacks':[es]}).mean()\n",
    "    score = ((scores*-1)**0.5)*-1\n",
    "    return score\n",
    "\n",
    "# Set hyperparameters spaces\n",
    "params_LSTM_ffnn ={\n",
    "    \n",
    "    'activation_0':(0, 4),\n",
    "    'activation_1':(0, 4),\n",
    "    'activation_2':(0, 4),\n",
    "    'activation_3':(0, 4),\n",
    "    'activation_4':(0, 4),\n",
    "    'activation_5':(0, 4),\n",
    "    \n",
    "    'lstm_neurons_0': (10, 500),\n",
    "    'lstm_neurons_1': (10, 500),\n",
    "    'lstm_neurons_2': (10, 500),\n",
    "    'lstm_neurons_3': (10, 500),\n",
    "    \n",
    "    'layers_lstm_1':(1,5),\n",
    "    'layers_lstm_2':(1,5),\n",
    "    'layers_lstm_3':(1,5),\n",
    "    \n",
    "    'ffnn_neurons_0': (10, 500),\n",
    "    'ffnn_neurons_1': (10, 500),\n",
    "    'ffnn_neurons_2': (10, 500),\n",
    "    'ffnn_neurons_3': (10, 500),\n",
    "\n",
    "    'layers_ffnn_1':(1,5),\n",
    "    'layers_ffnn_2':(1,5),\n",
    "    'layers_ffnn_3':(1,5),\n",
    "    \n",
    "    'merged_layer':(1,5),\n",
    "    'dense_f_neurons': (10, 500),\n",
    "    'output_neurons': (10, 500),\n",
    "\n",
    "#     'dropout_lstm':(0,1),\n",
    "#     'dropout_rate_lstm':(0,.5),\n",
    "    \n",
    "#     'dropout_ffnn':(0,1),\n",
    "#     'dropout_rate_ffnn':(0,.5),\n",
    "    \n",
    "    'batch_size':(8, 50),\n",
    "    'epochs':(10, 50)\n",
    "}\n",
    "\n",
    "nn_bo_LSTM_ffnn = BayesianOptimization(nn_re_bo, params_LSTM_ffnn, random_state=123)\n",
    "nn_bo_LSTM_ffnn.maximize(init_points=4, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters\n",
    "params_LSTM_ffnn = LSTM_ffnn.max['params']\n",
    "\n",
    "params_LSTM_ffnn['lstm_neurons_0'] = round(params_LSTM_ffnn['lstm_neurons_0'])\n",
    "params_LSTM_ffnn['lstm_neurons_1'] = round(params_LSTM_ffnn['lstm_neurons_1'])\n",
    "params_LSTM_ffnn['lstm_neurons_2'] = round(params_LSTM_ffnn['lstm_neurons_2'])\n",
    "params_LSTM_ffnn['lstm_neurons_3'] = round(params_LSTM_ffnn['lstm_neurons_3'])\n",
    "\n",
    "params_LSTM_ffnn['ffnn_neurons_0'] = round(params_LSTM_ffnn['ffnn_neurons_0'])\n",
    "params_LSTM_ffnn['ffnn_neurons_1'] = round(params_LSTM_ffnn['ffnn_neurons_1'])\n",
    "params_LSTM_ffnn['ffnn_neurons_2'] = round(params_LSTM_ffnn['ffnn_neurons_2'])\n",
    "params_LSTM_ffnn['ffnn_neurons_3'] = round(params_LSTM_ffnn['ffnn_neurons_3'])\n",
    "\n",
    "params_LSTM_ffnn['activation_0'] = activationL[floor(params_LSTM_ffnn['activation_0'])]\n",
    "params_LSTM_ffnn['activation_1'] = activationL[floor(params_LSTM_ffnn['activation_1'])]\n",
    "params_LSTM_ffnn['activation_2'] = activationL[floor(params_LSTM_ffnn['activation_2'])]\n",
    "params_LSTM_ffnn['activation_3'] = activationL[floor(params_LSTM_ffnn['activation_3'])]\n",
    "params_LSTM_ffnn['activation_4'] = activationL[floor(params_LSTM_ffnn['activation_4'])]\n",
    "params_LSTM_ffnn['activation_5'] = activationL[floor(params_LSTM_ffnn['activation_5'])]\n",
    "\n",
    "params_LSTM_ffnn['batch_size'] = round(params_LSTM_ffnn['batch_size'])\n",
    "params_LSTM_ffnn['epochs'] = round(params_LSTM_ffnn['epochs'])\n",
    "\n",
    "params_LSTM_ffnn['layers_ffnn_1'] = round(params_LSTM_ffnn['layers_ffnn_1'])\n",
    "params_LSTM_ffnn['layers_ffnn_2'] = round(params_LSTM_ffnn['layers_ffnn_2'])\n",
    "params_LSTM_ffnn['layers_ffnn_3'] = round(params_LSTM_ffnn['layers_ffnn_3'])\n",
    "\n",
    "params_LSTM_ffnn['layers_lstm_1'] = round(params_LSTM_ffnn['layers_lstm_1'])\n",
    "params_LSTM_ffnn['layers_lstm_2'] = round(params_LSTM_ffnn['layers_lstm_2'])\n",
    "params_LSTM_ffnn['layers_lstm_3'] = round(params_LSTM_ffnn['layers_lstm_3'])\n",
    "\n",
    "params_LSTM_ffnn['merged_layer'] = round(params_LSTM_ffnn['merged_layer'])\n",
    "params_LSTM_ffnn['dense_f_neurons'] = round(params_LSTM_ffnn['dense_f_neurons'])\n",
    "params_LSTM_ffnn['output_neurons'] = round(params_LSTM_ffnn['output_neurons'])\n",
    "\n",
    "params_LSTM_ffnn['dropout_ffnn'] = round(params_nn_ffnn['dropout_ffnn'])\n",
    "params_LSTM_ffnn['dropout_rate_ffnn'] = round(params_nn_ffnn['dropout_rate_ffnn'])\n",
    "\n",
    "params_LSTM_ffnn['dropout_lstm'] = round(params_nn_ffnn['dropout_lstm'])\n",
    "params_LSTM_ffnn['dropout_rate_lstm'] = round(params_nn_ffnn['dropout_rate_lstm'])\n",
    "\n",
    "params_LSTM_ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24adf84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b370b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6fa1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff1979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3632315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed16ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9897b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0ad9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f0bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdaea3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8294eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
