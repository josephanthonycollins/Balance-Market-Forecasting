{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import importlib\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from math import floor\n",
    "from bayes_opt import BayesianOptimization\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "#tensorflow &keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "\n",
    "#sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing as prep\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format=\"%m/%d/%Y %H:%M\"\n",
    "date_parse = lambda date: dt.datetime.strptime(date, date_format)\n",
    "dat = pd.read_csv(\"C:/Users/ciara/OneDrive/Documents/BM_data.csv\", index_col=\"SettlementPeriod\", parse_dates=True, date_parser=date_parse)\n",
    "\n",
    "dat = dat.drop([\"index\"], axis=1)\n",
    "dat=pd.DataFrame(dat)\n",
    "dat=dat.bfill(axis ='rows')\n",
    "dat=dat.ffill(axis ='rows')\n",
    "dat=dat._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dat.iloc[:, 0:16]\n",
    "X=dat.iloc[:,16:]\n",
    "X_train=X.iloc[:20450,:]\n",
    "Y_train=Y.iloc[:20450,:]\n",
    "X_test=X.iloc[20450:20451,:]\n",
    "Y_test=Y.iloc[20450:20451,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_train1=X_train[[\"lag_-3x\", \"lag_-4x\",\"lag_-5x\",\"lag_-6x\",\"lag_-7x\", \"lag_-8x\",\"lag_-9x\",\"lag_-10x\",\"lag_-11x\", \"lag_-12x\",\"lag_-13x\",\"lag_-14x\",\"lag_-15x\", \"lag_-16x\",\"lag_-17x\",\"lag_-18x\",\"lag_-19x\", \"lag_-20x\",\"lag_-21x\",\"lag_-22x\",\"lag_-23x\", \"lag_-24x\",\"lag_-25x\",\"lag_-26x\",\"lag_-27x\", \"lag_-28x\",\"lag_-29x\",\"lag_-30x\",\"lag_-31x\", \"lag_-32x\",\"lag_-33x\",\"lag_-34x\",\"lag_-35x\", \"lag_-36x\",\"lag_-37x\",\"lag_-38x\",\"lag_-39x\", \"lag_-40x\",\"lag_-41x\",\"lag_-42x\",\"lag_-43x\", \"lag_-44x\",\"lag_-45x\",\"lag_-46x\",\"lag_-47x\", \"lag_-48x\",\"lag_-49x\",\"lag_-50x\",\"lag_-51x\"]]\n",
    "# rnn_train6=X_train[[\"lag_2x\",\"lag_3x\",\"lag_4x\",\"lag_5x\",\"lag_6x\",\"lag_7x\",\"lag_8x\",\"lag_9x\",\"lag_10x\",\"lag_11x\",\"lag_12x\",\"lag_13x\",\"lag_14x\",\"lag_15x\",\"lag_16x\",\"lag_17x\"]]\n",
    "# rnn_train11=X_train[[\"lag_0x4\",\"lag_0x5\"]]\n",
    "rnn_train1_a=X_train[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\"]]\n",
    "rnn_train1_b=X_train[[\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\"]]\n",
    "rnn_train1_c=X_train[[\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "\n",
    "rnn_train2_a=X_train[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\"]]\n",
    "rnn_train2_b=X_train[[\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\"]]\n",
    "rnn_train2_c=X_train[[\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "\n",
    "rnn_train3_a=X_train[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\"]]\n",
    "rnn_train3_b=X_train[[\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\"]]\n",
    "rnn_train3_c=X_train[[\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "\n",
    "rnn_train4_a=X_train[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\"]]\n",
    "rnn_train4_b=X_train[[\"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\"]]\n",
    "rnn_train4_c=X_train[[\"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "\n",
    "rnn_train5_a=X_train[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\"]]\n",
    "rnn_train5_b=X_train[[\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\"]]\n",
    "rnn_train5_c=X_train[[\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "rnn_train6=X_train[[\"lag_2x7\",\"lag_3x7\",\"lag_4x7\",\"lag_5x7\",\"lag_6x7\",\"lag_7x7\",\"lag_8x7\",\"lag_9x7\",\"lag_10x7\",\"lag_11x7\",\"lag_12x7\",\"lag_13x7\",\"lag_14x7\",\"lag_15x7\",\"lag_16x7\",\"lag_17x7\"]]\n",
    "rnn_train7=X_train[[\"lag_2x8.1\",\"lag_3x8\",\"lag_4x8\",\"lag_5x8\",\"lag_6x8\",\"lag_7x8\",\"lag_8x8\",\"lag_9x8\",\"lag_10x8\",\"lag_11x8\",\"lag_12x8\",\"lag_13x8\",\"lag_14x8\",\"lag_15x8\",\"lag_16x8\",\"lag_17x8\"]]\n",
    "rnn_train8=X_train[[\"lag_2x9\",\"lag_3x9\",\"lag_4x9\",\"lag_5x9\",\"lag_6x9\",\"lag_7x9\",\"lag_8x9\",\"lag_9x9\",\"lag_10x9\",\"lag_11x9\",\"lag_12x9\",\"lag_13x9\",\"lag_14x9\",\"lag_15x9\",\"lag_16x9\",\"lag_17x9\"]]\n",
    "rnn_train9=X_train[[\"lag_2x10\",\"lag_3x10\",\"lag_4x10\",\"lag_5x10\",\"lag_6x10\",\"lag_7x10\",\"lag_8x10\",\"lag_9x10\",\"lag_10x10\",\"lag_11x10\",\"lag_12x10\",\"lag_13x10\",\"lag_14x10\",\"lag_15x10\",\"lag_16x10\",\"lag_17x10\"]]\n",
    "rnn_train10=X_train[[\"lag_2x11\",\"lag_3x11\",\"lag_4x11\",\"lag_5x11\",\"lag_6x11\",\"lag_7x11\",\"lag_8x11\",\"lag_9x11\",\"lag_10x11\",\"lag_11x11\",\"lag_12x11\",\"lag_13x11\",\"lag_14x11\",\"lag_15x11\",\"lag_16x11\",\"lag_17x11\"]]\n",
    "\n",
    "\n",
    "\n",
    "rnn_test1_a=X_test[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\"]]\n",
    "rnn_test1_b=X_test[[\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\"]]\n",
    "rnn_test1_c=X_test[[\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "\n",
    "rnn_test2_a=X_test[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\"]]\n",
    "rnn_test2_b=X_test[[\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\"]]\n",
    "rnn_test2_c=X_test[[\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "\n",
    "rnn_test3_a=X_test[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\"]]\n",
    "rnn_test3_b=X_test[[\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\"]]\n",
    "rnn_test3_c=X_test[[\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "\n",
    "rnn_test4_a=X_test[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\"]]\n",
    "rnn_test4_b=X_test[[\"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\"]]\n",
    "rnn_test4_c=X_test[[\"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "\n",
    "rnn_test5_a=X_test[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\"]]\n",
    "rnn_test5_b=X_test[[\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\"]]\n",
    "rnn_test5_c=X_test[[\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "rnn_test6=X_test[[\"lag_2x7\",\"lag_3x7\",\"lag_4x7\",\"lag_5x7\",\"lag_6x7\",\"lag_7x7\",\"lag_8x7\",\"lag_9x7\",\"lag_10x7\",\"lag_11x7\",\"lag_12x7\",\"lag_13x7\",\"lag_14x7\",\"lag_15x7\",\"lag_16x7\",\"lag_17x7\"]]\n",
    "rnn_test7=X_test[[\"lag_2x8.1\",\"lag_3x8\",\"lag_4x8\",\"lag_5x8\",\"lag_6x8\",\"lag_7x8\",\"lag_8x8\",\"lag_9x8\",\"lag_10x8\",\"lag_11x8\",\"lag_12x8\",\"lag_13x8\",\"lag_14x8\",\"lag_15x8\",\"lag_16x8\",\"lag_17x8\"]]\n",
    "rnn_test8=X_test[[\"lag_2x9\",\"lag_3x9\",\"lag_4x9\",\"lag_5x9\",\"lag_6x9\",\"lag_7x9\",\"lag_8x9\",\"lag_9x9\",\"lag_10x9\",\"lag_11x9\",\"lag_12x9\",\"lag_13x9\",\"lag_14x9\",\"lag_15x9\",\"lag_16x9\",\"lag_17x9\"]]\n",
    "rnn_test9=X_test[[\"lag_2x10\",\"lag_3x10\",\"lag_4x10\",\"lag_5x10\",\"lag_6x10\",\"lag_7x10\",\"lag_8x10\",\"lag_9x10\",\"lag_10x10\",\"lag_11x10\",\"lag_12x10\",\"lag_13x10\",\"lag_14x10\",\"lag_15x10\",\"lag_16x10\",\"lag_17x10\"]]\n",
    "rnn_test10=X_test[[\"lag_2x11\",\"lag_3x11\",\"lag_4x11\",\"lag_5x11\",\"lag_6x11\",\"lag_7x11\",\"lag_8x11\",\"lag_9x11\",\"lag_10x11\",\"lag_11x11\",\"lag_12x11\",\"lag_13x11\",\"lag_14x11\",\"lag_15x11\",\"lag_16x11\",\"lag_17x11\"]]\n",
    "\n",
    "rnn_Y=Y_train[[\"lag_2y\", \"lag_3y\", \"lag_4y\", \"lag_5y\", \"lag_6y\", \"lag_7y\", \"lag_8y\", \"lag_9y\", \"lag_10y\", \"lag_11y\", \"lag_12y\", \"lag_13y\", \"lag_14y\", \"lag_15y\", \"lag_16y\", \"lag_17y\"]]\n",
    "\n",
    "X_scaler1_a = preprocessing.MinMaxScaler()\n",
    "X_scaler1_b = preprocessing.MinMaxScaler()\n",
    "X_scaler1_c = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_scaler2_a = preprocessing.MinMaxScaler()\n",
    "X_scaler2_b = preprocessing.MinMaxScaler()\n",
    "X_scaler2_c = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_scaler3_a = preprocessing.MinMaxScaler()\n",
    "X_scaler3_b = preprocessing.MinMaxScaler()\n",
    "X_scaler3_c = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_scaler4_a = preprocessing.MinMaxScaler()\n",
    "X_scaler4_b = preprocessing.MinMaxScaler()\n",
    "X_scaler4_c = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_scaler5_a = preprocessing.MinMaxScaler()\n",
    "X_scaler5_b = preprocessing.MinMaxScaler()\n",
    "X_scaler5_c = preprocessing.MinMaxScaler()\n",
    "\n",
    "\n",
    "X_scaler6 = preprocessing.MinMaxScaler()\n",
    "X_scaler7 = preprocessing.MinMaxScaler()\n",
    "X_scaler8 = preprocessing.MinMaxScaler()\n",
    "X_scaler9 = preprocessing.MinMaxScaler()\n",
    "X_scaler10 = preprocessing.MinMaxScaler()\n",
    "\n",
    "Y_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "rnn_scaled_train1_a = X_scaler1_a.fit_transform(rnn_train1_a)\n",
    "rnn_scaled_train1_b = X_scaler1_b.fit_transform(rnn_train1_b)\n",
    "rnn_scaled_train1_c = X_scaler1_c.fit_transform(rnn_train1_c)\n",
    "\n",
    "rnn_scaled_train2_a = X_scaler2_a.fit_transform(rnn_train2_a)\n",
    "rnn_scaled_train2_b = X_scaler2_b.fit_transform(rnn_train2_b)\n",
    "rnn_scaled_train2_c = X_scaler2_c.fit_transform(rnn_train2_c)\n",
    "\n",
    "rnn_scaled_train3_a = X_scaler3_a.fit_transform(rnn_train3_a)\n",
    "rnn_scaled_train3_b = X_scaler3_b.fit_transform(rnn_train3_b)\n",
    "rnn_scaled_train3_c = X_scaler3_c.fit_transform(rnn_train3_c)\n",
    "\n",
    "rnn_scaled_train4_a = X_scaler4_a.fit_transform(rnn_train4_a)\n",
    "rnn_scaled_train4_b = X_scaler4_b.fit_transform(rnn_train4_b)\n",
    "rnn_scaled_train4_c = X_scaler4_c.fit_transform(rnn_train4_c)\n",
    "\n",
    "rnn_scaled_train5_a = X_scaler5_a.fit_transform(rnn_train5_a)\n",
    "rnn_scaled_train5_b = X_scaler5_b.fit_transform(rnn_train5_b)\n",
    "rnn_scaled_train5_c = X_scaler5_c.fit_transform(rnn_train5_c)\n",
    "\n",
    "rnn_scaled_train6 = X_scaler6.fit_transform(rnn_train6)\n",
    "rnn_scaled_train7 = X_scaler7.fit_transform(rnn_train7)\n",
    "rnn_scaled_train8 = X_scaler8.fit_transform(rnn_train8)\n",
    "rnn_scaled_train9 = X_scaler9.fit_transform(rnn_train9)\n",
    "rnn_scaled_train10 = X_scaler10.fit_transform(rnn_train10)\n",
    "\n",
    "Y_train_Scaled   = Y_scaler.fit_transform(Y_train)\n",
    "\n",
    "X_train_Scaled = np.hstack(\n",
    "    (rnn_scaled_train1_a, rnn_scaled_train1_b, rnn_scaled_train1_c, rnn_scaled_train2_a, rnn_scaled_train2_b, rnn_scaled_train2_c,\n",
    "     rnn_scaled_train3_a, rnn_scaled_train3_b, rnn_scaled_train3_c, rnn_scaled_train4_a, rnn_scaled_train4_b, rnn_scaled_train4_c,\n",
    "     rnn_scaled_train5_a, rnn_scaled_train5_b, rnn_scaled_train5_c,rnn_scaled_train6,rnn_scaled_train7, rnn_scaled_train8,\n",
    "     rnn_scaled_train9, rnn_scaled_train10)\n",
    ").reshape(rnn_train6.shape[0], 20, 16).transpose(0, 2, 1)\n",
    "\n",
    "X_test_Scaled = np.hstack(\n",
    "    (X_scaler1_a.transform(rnn_test1_a),X_scaler1_b.transform(rnn_test1_b),X_scaler1_c.transform(rnn_test1_c),\n",
    "     X_scaler2_a.transform(rnn_test2_a),X_scaler2_b.transform(rnn_test2_b),X_scaler2_c.transform(rnn_test2_c),\n",
    "     X_scaler3_a.transform(rnn_test3_a),X_scaler3_b.transform(rnn_test3_b),X_scaler3_c.transform(rnn_test3_c),\n",
    "     X_scaler4_a.transform(rnn_test4_a),X_scaler4_b.transform(rnn_test4_b),X_scaler4_c.transform(rnn_test4_c),\n",
    "     X_scaler5_a.transform(rnn_test5_a),X_scaler5_b.transform(rnn_test5_b),X_scaler5_c.transform(rnn_test5_c),\n",
    "     X_scaler6.transform(rnn_test6),X_scaler7.transform(rnn_test7),X_scaler8.transform(rnn_test8),\n",
    "     X_scaler9.transform(rnn_test9), X_scaler10.transform(rnn_test10))\n",
    ").reshape(rnn_test6.shape[0], 20, 16).transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_acc = make_scorer(mean_absolute_error)\n",
    "mse = make_scorer(MSE, greater_is_better=False)\n",
    "i_shape=(None,X_train_Scaled.shape[1], X_train_Scaled.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Scaled.shape\n",
    "i_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model check before hyperparameter run\n",
    "\n",
    "# def create_model():\n",
    "#             nn = Sequential()\n",
    "#             for i in range(3):\n",
    "#                 nn.add(GRU(64, return_sequences= True, input_shape=i_shape))\n",
    "                \n",
    "#             for i in range(2):\n",
    "#                 nn.add(Dense(128, activation=LeakyReLU))\n",
    "   \n",
    "#             for i in range(1):\n",
    "#                 nn.add(GRU(256, return_sequences= True, input_shape=i_shape))\n",
    "            \n",
    "#             if 1 > 0.2:\n",
    "#                 nn.add(Dropout(0.15, seed=123))\n",
    "            \n",
    "#             for i in range(2):\n",
    "#                 nn.add(Dense(128, activation='tanh'))\n",
    "#             nn.add(GRU(64))\n",
    "#             nn.add(Dense(16))\n",
    "#             nn.compile(loss='mean_absolute_error', optimizer='Adam', metrics=['mean_absolute_error'])\n",
    "#             nn.build(i_shape)\n",
    "#             nn.summary()\n",
    "#             return nn\n",
    "        \n",
    "# es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=1, patience=20)        \n",
    "# nn_hyp = KerasRegressor(build_fn=create_model, epochs=2, batch_size=16,\n",
    "#                          verbose=0, callbacks=[es])\n",
    "# nn_hyp.fit(X_train_Scaled, Y_train_Scaled, verbose=1, validation_split=0.2)\n",
    "# preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict(X_test_Scaled).reshape(1,16)), index=Y_test.index)\n",
    "# mse = mean_squared_error(Y_test, preds_nn)\n",
    "# rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "# mae = mean_absolute_error(Y_test, preds_nn)\n",
    "# Error_1 = pd.DataFrame([mse, rmse, mae]).T\n",
    "# Error_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_neurons_0, lstm_neurons_1, lstm_neurons_2, neurons_0, neurons_1, dropout, dropout_rate,\n",
    "                 batch_size, epochs, layers1, layers2, layers3, layers4,activation_0,activation_1):\n",
    "            nn = Sequential()\n",
    "            for i in range(layers1):\n",
    "                nn.add(GRU(lstm_neurons_0, return_sequences= True, input_shape=i_shape))\n",
    "                \n",
    "            for i in range(layers2):\n",
    "                nn.add(Dense(neurons_0, activation=activation_0))\n",
    "   \n",
    "            for i in range(layers3):\n",
    "                nn.add(GRU(lstm_neurons_1, return_sequences= True, input_shape=i_shape))\n",
    "            \n",
    "            if dropout > 0.2:\n",
    "                nn.add(Dropout(dropout_rate, seed=123))\n",
    "            \n",
    "            for i in range(layers4):\n",
    "                nn.add(Dense(neurons_1, activation=activation_1))\n",
    "                \n",
    "            nn.add(GRU(lstm_neurons_2))                \n",
    "            nn.add(Dense(16))\n",
    "            nn.compile(loss='mean_absolute_error', optimizer='Adam', metrics=['mean_absolute_error'])\n",
    "            nn.build(i_shape)\n",
    "            nn.summary()\n",
    "            return nn\n",
    "        \n",
    "es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=0, patience=25)\n",
    "nn = KerasRegressor(build_fn=create_model,  verbose=0, callbacks=[es])\n",
    "# Set hyperparameters spaces\n",
    "params_nn ={\n",
    "    'neurons_0': (10, 500),\n",
    "    'activation_0':['relu', 'sigmoid',  'tanh', LeakyReLU],\n",
    "    'neurons_1': (10, 500),\n",
    "    'activation_1':['relu', 'sigmoid',  'tanh', LeakyReLU],\n",
    "    'lstm_neurons_0': (10, 500),\n",
    "    'lstm_neurons_1': (10, 500),\n",
    "    'lstm_neurons_2': (10, 500),\n",
    "    'layers1':(1,5),\n",
    "    'layers2':(1,5),\n",
    "    'layers3':(1,5),\n",
    "    'layers4':(1,5),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,.5),\n",
    "    'batch_size':(8, 50),\n",
    "    'epochs':(10, 200)\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=nn, cv=5, param_distributions=params_nn)\n",
    "grid_result = grid.fit(X_train_Scaled, Y_train_Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: \",\n",
    "      grid_result.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    nn = Sequential()\n",
    "    for i in range(grid_result.best_params_['layers1']):\n",
    "        nn.add(GRU(grid_result.best_params_['lstm_neurons_0'], return_sequences= True, input_shape=i_shape))\n",
    "        \n",
    "    for i in range(grid_result.best_params_['layers2']):\n",
    "        nn.add(Dense(grid_result.best_params_['neurons_0'], activation=grid_result.best_params_['activation_0']))\n",
    "\n",
    "    for i in range(grid_result.best_params_['layers3']):\n",
    "        nn.add(GRU(grid_result.best_params_['lstm_neurons_1'], return_sequences= True, input_shape=i_shape))\n",
    "        \n",
    "    if grid_result.best_params_['dropout'] > 0.2:\n",
    "        nn.add(Dropout(grid_result.best_params_['dropout_rate'], seed=123))\n",
    "        \n",
    "    for i in range(grid_result.best_params_['layers4']):\n",
    "        nn.add(Dense(grid_result.best_params_['neurons_1'], activation=grid_result.best_params_['activation_1']))\n",
    "    \n",
    "    nn.add(GRU(grid_result.best_params_['lstm_neurons_2']))                \n",
    "    nn.add(Dense(16))\n",
    "    nn.compile(loss='mean_absolute_error', optimizer='Adam', metrics=['mean_absolute_error'])\n",
    "    nn.build(i_shape)\n",
    "    nn.summary()\n",
    "    return nn\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=0, patience=20)        \n",
    "nn_hyp = KerasRegressor(build_fn=create_model, epochs=grid_result.best_params_['epochs'], batch_size=grid_result.best_params_['batch_size'],\n",
    "                         verbose=0, callbacks=[es])\n",
    "nn_hyp.fit(X_train_Scaled, Y_train_Scaled, verbose=0, validation_split=0.2)\n",
    "preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict(X_test_Scaled).reshape(1,16)), index=Y_test.index)\n",
    "mse = mean_squared_error(Y_test, pred_nn)\n",
    "rmse = sqrt(mean_squared_error(Y_test, pred_nn))\n",
    "mae = mean_absolute_error(Y_test, pred_nn)\n",
    "Error_1 = pd.DataFrame([mse, rmse, mae]).T\n",
    "Error_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors_000=[]\n",
    "n=20450\n",
    "a=0\n",
    "for i in range(0, 10, 1):\n",
    "    X=dat.iloc[a+i:, 16:]\n",
    "    Y=dat.iloc[a+i:, :16]\n",
    "    \n",
    "    X_train=X.iloc[:n,:]\n",
    "    Y_train=Y.iloc[:n,:]\n",
    "    X_test=X.iloc[n+15:n+16,:]\n",
    "    Y_test=Y.iloc[n+15:n+16,:]\n",
    "\n",
    "    # rnn_train1=X_train[[\"lag_-3x\", \"lag_-4x\",\"lag_-5x\",\"lag_-6x\",\"lag_-7x\", \"lag_-8x\",\"lag_-9x\",\"lag_-10x\",\"lag_-11x\", \"lag_-12x\",\"lag_-13x\",\"lag_-14x\",\"lag_-15x\", \"lag_-16x\",\"lag_-17x\",\"lag_-18x\",\"lag_-19x\", \"lag_-20x\",\"lag_-21x\",\"lag_-22x\",\"lag_-23x\", \"lag_-24x\",\"lag_-25x\",\"lag_-26x\",\"lag_-27x\", \"lag_-28x\",\"lag_-29x\",\"lag_-30x\",\"lag_-31x\", \"lag_-32x\",\"lag_-33x\",\"lag_-34x\",\"lag_-35x\", \"lag_-36x\",\"lag_-37x\",\"lag_-38x\",\"lag_-39x\", \"lag_-40x\",\"lag_-41x\",\"lag_-42x\",\"lag_-43x\", \"lag_-44x\",\"lag_-45x\",\"lag_-46x\",\"lag_-47x\", \"lag_-48x\",\"lag_-49x\",\"lag_-50x\",\"lag_-51x\"]]\n",
    "    rnn_train1=X_train[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\",\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\",\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "    rnn_train2=X_train[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\",\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\",\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "    rnn_train3=X_train[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\",\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\",\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "    rnn_train4=X_train[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\", \"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\", \"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "    rnn_train5=X_train[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\",\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\",\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "    rnn_test1=X_test[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\",\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\",\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "    rnn_test2=X_test[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\",\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\",\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "    rnn_test3=X_test[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\",\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\",\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "    rnn_test4=X_test[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\", \"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\", \"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "    rnn_test5=X_test[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\",\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\",\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "    rnn_Y=Y_train[[\"y\", \"lag_3y\", \"lag_4y\", \"lag_5y\", \"lag_6y\", \"lag_7y\", \"lag_8y\", \"lag_9y\", \"lag_10y\", \"lag_11y\", \"lag_12y\", \"lag_13y\", \"lag_14y\", \"lag_15y\", \"lag_16y\", \"lag_17y\"]]\n",
    "\n",
    "    X_scaler1 = preprocessing.MinMaxScaler()\n",
    "    X_scaler2 = preprocessing.MinMaxScaler()\n",
    "    X_scaler3 = preprocessing.MinMaxScaler()\n",
    "    X_scaler4 = preprocessing.MinMaxScaler()\n",
    "    X_scaler5 = preprocessing.MinMaxScaler()\n",
    "\n",
    "    Y_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    rnn_scaled_train1 = X_scaler1.fit_transform(rnn_train1)\n",
    "    rnn_scaled_train2 = X_scaler2.fit_transform(rnn_train2)\n",
    "    rnn_scaled_train3 = X_scaler3.fit_transform(rnn_train3)\n",
    "    rnn_scaled_train4 = X_scaler4.fit_transform(rnn_train4)\n",
    "    rnn_scaled_train5 = X_scaler5.fit_transform(rnn_train5)\n",
    "\n",
    "    Y_train_Scaled   = Y_scaler.fit_transform(Y_train)\n",
    "\n",
    "    X_train_Scaled = np.hstack(\n",
    "        (rnn_scaled_train1, rnn_scaled_train2, rnn_scaled_train3,\n",
    "         rnn_scaled_train4, rnn_scaled_train5)\n",
    "    ).reshape(rnn_train1.shape[0], 5, 48).transpose(0, 2, 1)\n",
    "\n",
    "    X_test_Scaled = np.hstack(\n",
    "        (X_scaler1.transform(rnn_test1), X_scaler2.transform(rnn_test2),\n",
    "         X_scaler3.transform(rnn_test3), X_scaler4.transform(rnn_test4),\n",
    "         X_scaler5.transform(rnn_test5))\n",
    "    ).reshape(rnn_test1.shape[0], 5, 48).transpose(0, 2, 1)\n",
    "    \n",
    "\n",
    "    def create_model():\n",
    "        nn = Sequential()\n",
    "        for i in range(grid_result.best_params_['layers1']):\n",
    "            nn.add(GRU(grid_result.best_params_['lstm_neurons_0'], return_sequences= True, input_shape=i_shape))\n",
    "        \n",
    "        for i in range(grid_result.best_params_['layers2']):\n",
    "            nn.add(Dense(grid_result.best_params_['neurons_0'], activation=grid_result.best_params_['activation_0']))\n",
    "\n",
    "        for i in range(grid_result.best_params_['layers3']):\n",
    "            nn.add(GRU(grid_result.best_params_['lstm_neurons_1'], return_sequences= True, input_shape=i_shape))\n",
    "        \n",
    "        if grid_result.best_params_['dropout'] > 0.2:\n",
    "            nn.add(Dropout(grid_result.best_params_['dropout_rate'], seed=123))\n",
    "        \n",
    "        for i in range(grid_result.best_params_['layers4']):\n",
    "            nn.add(Dense(grid_result.best_params_['neurons_1'], activation=grid_result.best_params_['activation_1']))\n",
    "    \n",
    "        nn.add(GRU(grid_result.best_params_['lstm_neurons_2']))                \n",
    "        nn.add(Dense(16))\n",
    "        nn.compile(loss='mean_absolute_error', optimizer='Adam', metrics=['mean_absolute_error'])\n",
    "        nn.build(i_shape)\n",
    "        nn.summary()\n",
    "        return nn\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='mean_absolute_error', mode='min', verbose=0, patience=20)        \n",
    "    nn_hyp = KerasRegressor(build_fn=create_model, epochs=grid_result.best_params_['epochs'], batch_size=grid_result.best_params_['batch_size'],\n",
    "                         verbose=0, callbacks=[es])\n",
    "\n",
    "    nn_hyp.fit(X_train_Scaled, Y_train_Scaled, verbose=0, validation_split=0.2)\n",
    "    preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict(X_test_Scaled).reshape(1,16)), index=Y_test.index)\n",
    "\n",
    "    mse = mean_squared_error(Y_test, preds_nn)\n",
    "    rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "    mae = mean_absolute_error(Y_test, preds_nn)\n",
    "    Error_i = ([mse, rmse, mae])\n",
    "    Errors_000.append(Error_i)\n",
    "    Errors_A=pd.DataFrame(Errors_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors_A.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Errors_A[2].mean())\n",
    "plt.plot(Errors_A[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
