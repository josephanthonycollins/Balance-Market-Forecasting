{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import importlib\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from math import floor\n",
    "from bayes_opt import BayesianOptimization\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "#tensorflow &keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "\n",
    "#sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing as prep\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format=\"%m/%d/%Y %H:%M\"\n",
    "date_parse = lambda date: dt.datetime.strptime(date, date_format)\n",
    "dat = pd.read_csv(\"C:/Users/ciara/OneDrive/Documents/BM_data.csv\", index_col=\"SettlementPeriod\", parse_dates=True, date_parser=date_parse)\n",
    "\n",
    "# dat = pd.read_csv(\"C:/Users/ciara/Downloads/TimerSeries1.csv\", index_col=\"DeliveryPeriod\", parse_dates=True, date_parser=date_parse)\n",
    "dat = dat.drop([\"index\"], axis=1)\n",
    "dat=pd.DataFrame(dat)\n",
    "dat=dat.bfill(axis ='rows')\n",
    "dat=dat.ffill(axis ='rows')\n",
    "dat=dat._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dat.iloc[:, 0:16]\n",
    "X=dat.iloc[:,16:]\n",
    "X_train=X.iloc[:43826,:]\n",
    "Y_train=Y.iloc[:43826,:]\n",
    "X_test=X.iloc[43826:43827,:]\n",
    "Y_test=Y.iloc[43826:43827,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_train1=X_train[[\"lag_-3x\", \"lag_-4x\",\"lag_-5x\",\"lag_-6x\",\"lag_-7x\", \"lag_-8x\",\"lag_-9x\",\"lag_-10x\",\"lag_-11x\", \"lag_-12x\",\"lag_-13x\",\"lag_-14x\",\"lag_-15x\", \"lag_-16x\",\"lag_-17x\",\"lag_-18x\",\"lag_-19x\", \"lag_-20x\",\"lag_-21x\",\"lag_-22x\",\"lag_-23x\", \"lag_-24x\",\"lag_-25x\",\"lag_-26x\",\"lag_-27x\", \"lag_-28x\",\"lag_-29x\",\"lag_-30x\",\"lag_-31x\", \"lag_-32x\",\"lag_-33x\",\"lag_-34x\",\"lag_-35x\", \"lag_-36x\",\"lag_-37x\",\"lag_-38x\",\"lag_-39x\", \"lag_-40x\",\"lag_-41x\",\"lag_-42x\",\"lag_-43x\", \"lag_-44x\",\"lag_-45x\",\"lag_-46x\",\"lag_-47x\", \"lag_-48x\",\"lag_-49x\",\"lag_-50x\",\"lag_-51x\"]]\n",
    "rnn_train1=X_train[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\",\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\",\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "rnn_train2=X_train[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\",\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\",\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "rnn_train3=X_train[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\",\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\",\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "rnn_train4=X_train[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\", \"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\", \"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "rnn_train5=X_train[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\",\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\",\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "rnn_test1=X_test[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\",\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\",\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "rnn_test2=X_test[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\",\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\",\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "rnn_test3=X_test[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\",\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\",\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "rnn_test4=X_test[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\", \"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\", \"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "rnn_test5=X_test[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\",\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\",\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "rnn_Y=Y_train[[\"y\", \"lag_3y\", \"lag_4y\", \"lag_5y\", \"lag_6y\", \"lag_7y\", \"lag_8y\", \"lag_9y\", \"lag_10y\", \"lag_11y\", \"lag_12y\", \"lag_13y\", \"lag_14y\", \"lag_15y\", \"lag_16y\", \"lag_17y\"]]\n",
    "\n",
    "X_scaler1 = preprocessing.MinMaxScaler()\n",
    "X_scaler2 = preprocessing.MinMaxScaler()\n",
    "X_scaler3 = preprocessing.MinMaxScaler()\n",
    "X_scaler4 = preprocessing.MinMaxScaler()\n",
    "X_scaler5 = preprocessing.MinMaxScaler()\n",
    "\n",
    "Y_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "rnn_scaled_train1 = X_scaler1.fit_transform(rnn_train1)\n",
    "rnn_scaled_train2 = X_scaler2.fit_transform(rnn_train2)\n",
    "rnn_scaled_train3 = X_scaler3.fit_transform(rnn_train3)\n",
    "rnn_scaled_train4 = X_scaler4.fit_transform(rnn_train4)\n",
    "rnn_scaled_train5 = X_scaler5.fit_transform(rnn_train5)\n",
    "\n",
    "Y_train_Scaled   = Y_scaler.fit_transform(Y_train)\n",
    "\n",
    "X_train_Scaled = np.hstack(\n",
    "    (rnn_scaled_train1, rnn_scaled_train2, rnn_scaled_train3,\n",
    "     rnn_scaled_train4, rnn_scaled_train5)\n",
    ").reshape(rnn_train1.shape[0], 5, 48).transpose(0, 2, 1)\n",
    "\n",
    "X_test_Scaled = np.hstack(\n",
    "    (X_scaler1.transform(rnn_test1), X_scaler2.transform(rnn_test2),\n",
    "     X_scaler3.transform(rnn_test3), X_scaler4.transform(rnn_test4),\n",
    "     X_scaler5.transform(rnn_test5))\n",
    ").reshape(rnn_test1.shape[0], 5, 48).transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_acc = make_scorer(mean_absolute_error)\n",
    "mse = make_scorer(MSE, greater_is_better=False)\n",
    "i_shape=(None,X_train_Scaled.shape[1], X_train_Scaled.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 48, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_Scaled.shape\n",
    "i_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "module_wrapper_5 (ModuleWrap (None, 48, 64)            17920     \n",
      "_________________________________________________________________\n",
      "module_wrapper_6 (ModuleWrap (None, 48, 64)            33024     \n",
      "_________________________________________________________________\n",
      "module_wrapper_7 (ModuleWrap (None, 48, 64)            33024     \n",
      "_________________________________________________________________\n",
      "module_wrapper_8 (ModuleWrap (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 118,032\n",
      "Trainable params: 118,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2192/2192 [==============================] - 66s 26ms/step - loss: 1.9184e-04 - mean_squared_error: 1.9184e-04 - val_loss: 7.9294e-04 - val_mean_squared_error: 7.9294e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2a1f81910>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model():\n",
    "        nn = Sequential()\n",
    "        for i in range(3):\n",
    "            nn.add(LSTM(64, return_sequences= True, input_shape=i_shape))\n",
    "#         for i in range(1):\n",
    "#             nn.add(Dense(100, activation='sigmoid'))\n",
    "#         if 0 > 0.5:\n",
    "#             nn.add(Dropout(0.5, seed=123))\n",
    "#         nn.add(Dense(100, activation='tanh'))\n",
    "#         for i in range(1):\n",
    "#             nn.add(Dense(10, activation='tanh'))\n",
    "#         for i in range(3):\n",
    "#             nn.add(Dense(10, activation='tanh'))\n",
    "        nn.add(LSTM(64))\n",
    "        nn.add(Dense(16))\n",
    "        nn.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mean_squared_error'])\n",
    "        nn.build(i_shape)\n",
    "        nn.summary()\n",
    "        return nn\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=20)\n",
    "nn_hyp = KerasRegressor(build_fn=create_model, epochs=1, batch_size=16,\n",
    "                         verbose=1, callbacks=[es])\n",
    "nn_hyp.fit(X_train_Scaled, Y_train_Scaled, verbose=1, validation_split=0.2)\n",
    "\n",
    "# preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict(X_test_Scaled).reshape(1,16)), index=Y_test.index)\n",
    "# mse = mean_squared_error(Y_test, preds_nn)\n",
    "# rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "# mae = mean_absolute_error(Y_test, preds_nn)\n",
    "# Error_1 = pd.DataFrame([mse, rmse, mae]).T\n",
    "# Error_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons_0, activation_0,neurons_2, activation_2, neurons_1, activation_1,neurons_3, activation_3,\n",
    "             optimizer, batch_size, epochs, layers1, layers2, layers3, dropout, dropout_rate):\n",
    "        nn = Sequential()\n",
    "        nn.add(Flatten(input_shape=i_shape))\n",
    "        nn.add(Dense(neurons_0, input_shape=i_shape, activation=activation_0))\n",
    "        for i in range(layers1):\n",
    "            nn.add(Dense(neurons_1, activation=activation_1))\n",
    "        if dropout > 0.2:\n",
    "            nn.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            nn.add(Dense(neurons_2, activation=activation_2))\n",
    "        for i in range(layers3):\n",
    "            nn.add(Dense(neurons_3, activation=activation_3))\n",
    "        nn.add(Dense(16))\n",
    "        nn.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "        return nn\n",
    "    \n",
    "es = EarlyStopping(monitor='mean_squared_error', mode='min', verbose=0, patience=25)\n",
    "nn = KerasRegressor(build_fn=create_model,  verbose=0, callbacks=[es])\n",
    "# Set hyperparameters spaces\n",
    "params_nn ={\n",
    "    'neurons_0': (10, 100),\n",
    "    'activation_0':['relu', 'sigmoid',  'tanh'],\n",
    "    'neurons_1': (10, 100),\n",
    "    'activation_1':['relu', 'sigmoid',  'tanh'],\n",
    "    'neurons_2': (10, 100),\n",
    "    'activation_2':['relu', 'sigmoid',  'tanh'],\n",
    "    'neurons_3': (10, 100),\n",
    "    'activation_3':['relu', 'sigmoid',  'tanh'],\n",
    "    'optimizer':['Adam'],\n",
    "    'batch_size':(16, 50),\n",
    "    'epochs':(10, 200),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'layers3':(1,3),\n",
    "\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,.5)\n",
    "}\n",
    "\n",
    "# nn_bo = BayesianOptimization(create_model, params_nn, random_state=123)\n",
    "# nn_bo.maximize(init_points=4, n_iter=10)\n",
    "grid = RandomizedSearchCV(estimator=nn, cv=8, param_distributions=params_nn)\n",
    "grid_result = grid.fit(X_train_Scaled, Y_train_Scaled)\n",
    "print(\"Best Score: \",\n",
    "      grid_result.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    nn = Sequential()\n",
    "    nn.add(Flatten(input_shape=i_shape))\n",
    "    nn.add(Dense(grid_result.best_params_['neurons_0'], input_shape=i_shape, activation=grid_result.best_params_['activation_0']))\n",
    "    for i in range(grid_result.best_params_['layers1']):\n",
    "        nn.add(Dense(grid_result.best_params_['neurons_1'], activation=grid_result.best_params_['activation_1']))\n",
    "    if grid_result.best_params_['dropout'] > 0.2:\n",
    "        nn.add(Dropout(grid_result.best_params_['dropout_rate'], seed=123))\n",
    "    for i in range(grid_result.best_params_['layers2']):\n",
    "        nn.add(Dense(grid_result.best_params_['neurons_2'], activation=grid_result.best_params_['activation_2']))\n",
    "    for i in range(grid_result.best_params_['layers3']):\n",
    "        nn.add(Dense(grid_result.best_params_['neurons_3'], activation=grid_result.best_params_['activation_3']))\n",
    "    nn.add(Dense(16))\n",
    "    nn.compile(loss='mean_squared_error', optimizer=grid_result.best_params_['optimizer'], metrics=['mean_squared_error'])\n",
    "    return nn\n",
    "\n",
    "es = EarlyStopping(monitor='mean_squared_error', mode='min', verbose=0, patience=20)        \n",
    "nn_hyp = KerasRegressor(build_fn=create_model, epochs=grid_result.best_params_['epochs'], batch_size=grid_result.best_params_['batch_size'],\n",
    "                         verbose=0, callbacks=[es])\n",
    "nn_hyp.fit(X_train_Scaled, Y_train_Scaled, verbose=0, validation_split=0.2)\n",
    "preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict(X_test_Scaled).reshape(1,16)), index=Y_test.index)\n",
    "mse = mean_squared_error(Y_test, pred_nn)\n",
    "rmse = sqrt(mean_squared_error(Y_test, pred_nn))\n",
    "mae = mean_absolute_error(Y_test, pred_nn)\n",
    "Error_1 = pd.DataFrame([mse, rmse, mae]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    nn = Sequential()\n",
    "    nn.add(Flatten(input_shape=i_shape))\n",
    "    nn.add(Dense(grid_result.best_params_['neurons_0'], input_shape=i_shape, activation=grid_result.best_params_['activation_0']))\n",
    "    for i in range(grid_result.best_params_['layers1']):\n",
    "        nn.add(Dense(grid_result.best_params_['neurons_1'], activation=grid_result.best_params_['activation_1']))\n",
    "    if grid_result.best_params_['dropout'] > 0.2:\n",
    "        nn.add(Dropout(grid_result.best_params_['dropout_rate'], seed=123))\n",
    "    for i in range(grid_result.best_params_['layers2']):\n",
    "        nn.add(Dense(grid_result.best_params_['neurons_2'], activation=grid_result.best_params_['activation_2']))\n",
    "    for i in range(grid_result.best_params_['layers3']):\n",
    "        nn.add(Dense(grid_result.best_params_['neurons_3'], activation=grid_result.best_params_['activation_3']))\n",
    "    nn.add(Dense(16))\n",
    "    nn.compile(loss='mean_squared_error', optimizer=grid_result.best_params_['optimizer'], metrics=['mean_squared_error'])\n",
    "    return nn\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='mean_squared_error', mode='min', verbose=0, patience=20)        \n",
    "nn_hyp = KerasRegressor(build_fn=create_model, epochs=grid_result.best_params_['epochs'], batch_size=grid_result.best_params_['batch_size'],\n",
    "                         verbose=0, callbacks=[es])\n",
    "nn_hyp.fit(X_train_Scaled, Y_train_Scaled, verbose=0, validation_split=0.2)\n",
    "preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict(X_test_Scaled).reshape(1,16)), index=Y_test.index)\n",
    "mse = mean_squared_error(Y_test, preds_nn)\n",
    "rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "mae = mean_absolute_error(Y_test, preds_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors_000=[]\n",
    "n=41000\n",
    "a=0\n",
    "for i in range(0, 10, 1):\n",
    "    X=dat.iloc[a+i:, 16:]\n",
    "    Y=dat.iloc[a+i:, :16]\n",
    "    \n",
    "    X_train=X.iloc[:n,:]\n",
    "    Y_train=Y.iloc[:n,:]\n",
    "    X_test=X.iloc[n:n+1,:]\n",
    "    Y_test=Y.iloc[n:n+1,:]\n",
    "\n",
    "    # rnn_train1=X_train[[\"lag_-3x\", \"lag_-4x\",\"lag_-5x\",\"lag_-6x\",\"lag_-7x\", \"lag_-8x\",\"lag_-9x\",\"lag_-10x\",\"lag_-11x\", \"lag_-12x\",\"lag_-13x\",\"lag_-14x\",\"lag_-15x\", \"lag_-16x\",\"lag_-17x\",\"lag_-18x\",\"lag_-19x\", \"lag_-20x\",\"lag_-21x\",\"lag_-22x\",\"lag_-23x\", \"lag_-24x\",\"lag_-25x\",\"lag_-26x\",\"lag_-27x\", \"lag_-28x\",\"lag_-29x\",\"lag_-30x\",\"lag_-31x\", \"lag_-32x\",\"lag_-33x\",\"lag_-34x\",\"lag_-35x\", \"lag_-36x\",\"lag_-37x\",\"lag_-38x\",\"lag_-39x\", \"lag_-40x\",\"lag_-41x\",\"lag_-42x\",\"lag_-43x\", \"lag_-44x\",\"lag_-45x\",\"lag_-46x\",\"lag_-47x\", \"lag_-48x\",\"lag_-49x\",\"lag_-50x\",\"lag_-51x\"]]\n",
    "    rnn_train1=X_train[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\",\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\",\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "    rnn_train2=X_train[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\",\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\",\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "    rnn_train3=X_train[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\",\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\",\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "    rnn_train4=X_train[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\", \"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\", \"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "    rnn_train5=X_train[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\",\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\",\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "    rnn_test1=X_test[[\"lag_-3x1\", \"lag_-4x1\",\"lag_-5x1\",\"lag_-6x1\",\"lag_-7x1\", \"lag_-8x1\",\"lag_-9x1\",\"lag_-10x1\",\"lag_-11x1\", \"lag_-12x1\",\"lag_-13x1\",\"lag_-14x1\",\"lag_-15x1\", \"lag_-16x1\",\"lag_-17x1\",\"lag_-18x1\",\"lag_-19x1\", \"lag_-20x1\",\"lag_-21x1\",\"lag_-22x1\",\"lag_-23x1\", \"lag_-24x1\",\"lag_-25x1\",\"lag_-26x1\",\"lag_-27x1\", \"lag_-28x1\",\"lag_-29x1\",\"lag_-30x1\",\"lag_-31x1\", \"lag_-32x1\",\"lag_-33x1\",\"lag_-34x1\",\"lag_-35x1\", \"lag_-36x1\",\"lag_-37x1\",\"lag_-38x1\",\"lag_-39x1\", \"lag_-40x1\",\"lag_-41x1\",\"lag_-42x1\",\"lag_-43x1\", \"lag_-44x1\",\"lag_-45x1\",\"lag_-46x1\",\"lag_-47x1\", \"lag_-48x1\",\"lag_-49x1\",\"lag_-50x1\"]]\n",
    "    rnn_test2=X_test[[\"lag_-3x2\", \"lag_-4x2\",\"lag_-5x2\",\"lag_-6x2\",\"lag_-7x2\", \"lag_-8x2\",\"lag_-9x2\",\"lag_-10x2\",\"lag_-11x2\", \"lag_-12x2\",\"lag_-13x2\",\"lag_-14x2\",\"lag_-15x2\", \"lag_-16x2\",\"lag_-17x2\",\"lag_-18x2\",\"lag_-19x2\", \"lag_-20x2\",\"lag_-21x2\",\"lag_-22x2\",\"lag_-23x2\", \"lag_-24x2\",\"lag_-25x2\",\"lag_-26x2\",\"lag_-27x2\", \"lag_-28x2\",\"lag_-29x2\",\"lag_-30x2\",\"lag_-31x2\", \"lag_-32x2\",\"lag_-33x2\",\"lag_-34x2\",\"lag_-35x2\", \"lag_-36x2\",\"lag_-37x2\",\"lag_-38x2\",\"lag_-39x2\", \"lag_-40x2\",\"lag_-41x2\",\"lag_-42x2\",\"lag_-43x2\", \"lag_-44x2\",\"lag_-45x2\",\"lag_-46x2\",\"lag_-47x2\", \"lag_-48x2\",\"lag_-49x2\",\"lag_-50x2\"]]\n",
    "    rnn_test3=X_test[[\"lag_-2x3\",\"lag_-3x3\", \"lag_-4x3\",\"lag_-5x3\",\"lag_-6x3\",\"lag_-7x3\", \"lag_-8x3\",\"lag_-9x3\",\"lag_-10x3\",\"lag_-11x3\", \"lag_-12x3\",\"lag_-13x3\",\"lag_-14x3\",\"lag_-15x3\", \"lag_-16x3\",\"lag_-17x3\",\"lag_-18x3\",\"lag_-19x3\", \"lag_-20x3\",\"lag_-21x3\",\"lag_-22x3\",\"lag_-23x3\", \"lag_-24x3\",\"lag_-25x3\",\"lag_-26x3\",\"lag_-27x3\", \"lag_-28x3\",\"lag_-29x3\",\"lag_-30x3\",\"lag_-31x3\", \"lag_-32x3\",\"lag_-33x3\",\"lag_-34x3\",\"lag_-35x3\", \"lag_-36x3\",\"lag_-37x3\",\"lag_-38x3\",\"lag_-39x3\", \"lag_-40x3\",\"lag_-41x3\",\"lag_-42x3\",\"lag_-43x3\", \"lag_-44x3\",\"lag_-45x3\",\"lag_-46x3\",\"lag_-47x3\", \"lag_-48x3\",\"lag_-49x3\"]]\n",
    "    rnn_test4=X_test[[\"lag_0x6\",\"lag_-1x6\",\"lag_-2x6\",\"lag_-3x6\", \"lag_-4x6\",\"lag_-5x6\",\"lag_-6x6\",\"lag_-7x6\", \"lag_-8x6\",\"lag_-9x6\",\"lag_-10x6\",\"lag_-11x6\", \"lag_-12x6\",\"lag_-13x6\",\"lag_-14x6\",\"lag_-15x6\", \"lag_-16x6\",\"lag_-17x6\",\"lag_-18x6\",\"lag_-19x6\", \"lag_-20x6\",\"lag_-21x6\",\"lag_-22x6\",\"lag_-23x6\", \"lag_-24x6\",\"lag_-25x6\",\"lag_-26x6\",\"lag_-27x6\", \"lag_-28x6\",\"lag_-29x6\",\"lag_-30x6\",\"lag_-31x6\", \"lag_-32x6\",\"lag_-33x6\",\"lag_-34x6\",\"lag_-35x6\", \"lag_-36x6\",\"lag_-37x6\",\"lag_-38x6\",\"lag_-39x6\", \"lag_-40x6\",\"lag_-41x6\",\"lag_-42x6\",\"lag_-43x6\", \"lag_-44x6\",\"lag_-45x6\",\"lag_-46x6\",\"lag_-47x6\"]]\n",
    "    rnn_test5=X_test[[\"lag_-2x12\",\"lag_-3x12\", \"lag_-4x12\",\"lag_-5x12\",\"lag_-6x12\",\"lag_-7x12\", \"lag_-8x12\",\"lag_-9x12\",\"lag_-10x12\",\"lag_-11x12\", \"lag_-12x12\",\"lag_-13x12\",\"lag_-14x12\",\"lag_-15x12\", \"lag_-16x12\",\"lag_-17x12\",\"lag_-18x12\",\"lag_-19x12\", \"lag_-20x12\",\"lag_-21x12\",\"lag_-22x12\",\"lag_-23x12\", \"lag_-24x12\",\"lag_-25x12\",\"lag_-26x12\",\"lag_-27x12\", \"lag_-28x12\",\"lag_-29x12\",\"lag_-30x12\",\"lag_-31x12\", \"lag_-32x12\",\"lag_-33x12\",\"lag_-34x12\",\"lag_-35x12\", \"lag_-36x12\",\"lag_-37x12\",\"lag_-38x12\",\"lag_-39x12\", \"lag_-40x12\",\"lag_-41x12\",\"lag_-42x12\",\"lag_-43x12\", \"lag_-44x12\",\"lag_-45x12\",\"lag_-46x12\",\"lag_-47x12\", \"lag_-48x12\",\"lag_-49x12\"]]\n",
    "\n",
    "    rnn_Y=Y_train[[\"y\", \"lag_3y\", \"lag_4y\", \"lag_5y\", \"lag_6y\", \"lag_7y\", \"lag_8y\", \"lag_9y\", \"lag_10y\", \"lag_11y\", \"lag_12y\", \"lag_13y\", \"lag_14y\", \"lag_15y\", \"lag_16y\", \"lag_17y\"]]\n",
    "\n",
    "    X_scaler1 = preprocessing.MinMaxScaler()\n",
    "    X_scaler2 = preprocessing.MinMaxScaler()\n",
    "    X_scaler3 = preprocessing.MinMaxScaler()\n",
    "    X_scaler4 = preprocessing.MinMaxScaler()\n",
    "    X_scaler5 = preprocessing.MinMaxScaler()\n",
    "\n",
    "    Y_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    rnn_scaled_train1 = X_scaler1.fit_transform(rnn_train1)\n",
    "    rnn_scaled_train2 = X_scaler2.fit_transform(rnn_train2)\n",
    "    rnn_scaled_train3 = X_scaler3.fit_transform(rnn_train3)\n",
    "    rnn_scaled_train4 = X_scaler4.fit_transform(rnn_train4)\n",
    "    rnn_scaled_train5 = X_scaler5.fit_transform(rnn_train5)\n",
    "\n",
    "    Y_train_Scaled   = Y_scaler.fit_transform(Y_train)\n",
    "\n",
    "    X_train_Scaled = np.hstack(\n",
    "        (rnn_scaled_train1, rnn_scaled_train2, rnn_scaled_train3,\n",
    "         rnn_scaled_train4, rnn_scaled_train5)\n",
    "    ).reshape(rnn_train1.shape[0], 5, 48).transpose(0, 2, 1)\n",
    "\n",
    "    X_test_Scaled = np.hstack(\n",
    "        (X_scaler1.transform(rnn_test1), X_scaler2.transform(rnn_test2),\n",
    "         X_scaler3.transform(rnn_test3), X_scaler4.transform(rnn_test4),\n",
    "         X_scaler5.transform(rnn_test5))\n",
    "    ).reshape(rnn_test1.shape[0], 5, 48).transpose(0, 2, 1)\n",
    "    \n",
    "\n",
    "    def create_model():\n",
    "        nn = Sequential()\n",
    "        nn.add(Flatten(input_shape=i_shape))\n",
    "        nn.add(Dense(grid_result.best_params_['neurons_0'], input_shape=i_shape, activation=grid_result.best_params_['activation_0']))\n",
    "        for i in range(grid_result.best_params_['layers1']):\n",
    "            nn.add(Dense(grid_result.best_params_['neurons_1'], activation=grid_result.best_params_['activation_1']))\n",
    "        if grid_result.best_params_['dropout'] > 0.2:\n",
    "            nn.add(Dropout(grid_result.best_params_['dropout_rate'], seed=123))\n",
    "        for i in range(grid_result.best_params_['layers2']):\n",
    "            nn.add(Dense(grid_result.best_params_['neurons_2'], activation=grid_result.best_params_['activation_2']))\n",
    "        for i in range(grid_result.best_params_['layers3']):\n",
    "            nn.add(Dense(grid_result.best_params_['neurons_3'], activation=grid_result.best_params_['activation_3']))\n",
    "        nn.add(Dense(16))\n",
    "        nn.compile(loss='mean_squared_error', optimizer=grid_result.best_params_['optimizer'], metrics=['mean_squared_error'])\n",
    "        return nn\n",
    "        \n",
    "    es = EarlyStopping(monitor='mean_squared_error', mode='min', verbose=0, patience=20)        \n",
    "    nn_hyp = KerasRegressor(build_fn=create_model, epochs=grid_result.best_params_['epochs'], batch_size=grid_result.best_params_['batch_size'],\n",
    "                             verbose=0, callbacks=[es])\n",
    "\n",
    "    nn_hyp.fit(X_train_Scaled, Y_train_Scaled, verbose=0, validation_split=0.2)\n",
    "    preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict(X_test_Scaled).reshape(1,16)), index=Y_test.index)\n",
    "\n",
    "    mse = mean_squared_error(Y_test, preds_nn)\n",
    "    rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "    mae = mean_absolute_error(Y_test, preds_nn)\n",
    "    Error_i = ([mse, rmse, mae])\n",
    "    Errors_000.append(Error_i)\n",
    "    Errors_A=pd.DataFrame(Errors_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors_A.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_shape=(X_train_Scaled.shape[0],X_train_Scaled.shape[1], X_train_Scaled.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "        nn = Sequential()\n",
    "        nn.add(Flatten(input_shape=i_shape))\n",
    "        for i in range(1):\n",
    "            nn.add(LSTM(64, input_shape=i_shape))\n",
    "#         for i in range(1):\n",
    "#             nn.add(Dense(100, activation='sigmoid'))\n",
    "#         if 0 > 0.5:\n",
    "#             nn.add(Dropout(0.5, seed=123))\n",
    "#         nn.add(Dense(100, activation='tanh'))\n",
    "#         for i in range(1):\n",
    "#             nn.add(Dense(10, activation='tanh'))\n",
    "#         for i in range(3):\n",
    "#             nn.add(Dense(10, activation='tanh'))\n",
    "        nn.add(Dense(16))\n",
    "        nn.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mean_squared_error'])\n",
    "        nn.build(i_shape)\n",
    "        nn.summary()\n",
    "        return nn\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=20)\n",
    "nn_hyp = KerasRegressor(build_fn=create_model, epochs=50, batch_size=16,\n",
    "                         verbose=1, callbacks=[es])\n",
    "nn_hyp.fit(X_train_Scaled, Y_train_Scaled, verbose=1, validation_split=0.2)\n",
    "\n",
    "preds_nn = pd.DataFrame(Y_scaler.inverse_transform(nn_hyp.predict(X_test_Scaled).reshape(1,16)), index=Y_test.index)\n",
    "mse = mean_squared_error(Y_test, preds_nn)\n",
    "rmse = sqrt(mean_squared_error(Y_test, preds_nn))\n",
    "mae = mean_absolute_error(Y_test, preds_nn)\n",
    "Error_1 = pd.DataFrame([mse, rmse, mae]).T\n",
    "Error_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors_A[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Errors_A[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors_A.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
